{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from collections import Counter\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../input/\"\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "test_file = os.path.join(data_dir, \"test.csv\")\n",
    "embedding_size = 300\n",
    "max_len = 50\n",
    "max_features = 100000\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['how did quebec nationalists see their province as a nation in the 1960s?',\n",
       "       'do you have an adopted dog, how would you encourage people to adopt and not shop?',\n",
       "       'why does velocity affect time? does velocity affect space geometry?',\n",
       "       'how did otto von guericke used the magdeburg hemispheres?',\n",
       "       'can i convert montra helicon d to a mountain bike by just changing the tyres?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_file)\n",
    "# test_df = pd.read_csv(test_file)\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "# print(\"Test shape : \",test_df.shape)\n",
    "\n",
    "# data cleaning\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].str.lower()\n",
    "# test_df[\"question_text\"] = test_df[\"question_text\"].str.lower()\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_NA_\").values\n",
    "# test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "train_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[9, 48, 6683, 7219, 158, 55, 6107, 36, 4, 1206, 6, 1, 8333],\n",
       " [11, 14, 24, 29, 3864, 498, 9, 35, 14, 3672, 37, 5, 3089, 10, 44, 1846],\n",
       " [16, 26, 2002, 374, 70, 26, 2002, 374, 451, 5546],\n",
       " [9, 48, 13005, 8284, 52192, 119, 1, 39877, 28269],\n",
       " [15, 8, 1130, 42987, 99430, 911, 5, 4, 3133, 1533, 46, 96, 1465, 1, 9340]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 加入30个停用词\n",
    "# filters = []\n",
    "# standard_filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n'\n",
    "# for s in standard_filters:\n",
    "#     filters.append(s)\n",
    "# stop_words = ['does', 'a', 'that', 'to', 'or', 'in', 'if', 'the', 'how', 'can', 'have', 'and', 'of', 'what', 'you', 'be', 'from', 'an',\\\n",
    "#               'why', 'on', 'with', 'which', 'are', 'your', 'do', 'my', 'i', 'is', 'it', 'for']\n",
    "# filters.extend(stop_words)\n",
    "# print(filters)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "\n",
    "train_Y = train_df['target'].values\n",
    "print(np.sum(train_Y))\n",
    "\n",
    "# remove_words = []\n",
    "# for x in train_X:\n",
    "#     remove_words.append([i for i in x if i>40])\n",
    "# train_X = remove_words\n",
    "train_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SPLIT_SEED = 2018\n",
    "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=DATA_SPLIT_SEED).split(train_X, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for x in train_X:\n",
    "    if len(x) == 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正样本欠采样，负样本数据增强\n",
    "def data_augmentation(X, Y, under_sample=200000, aug=2):\n",
    "    \"\"\"\n",
    "    under_sample: 欠采样个数\n",
    "    aug: 数据增强倍数\n",
    "    \"\"\"\n",
    "    pos_X = []\n",
    "    neg_X = []\n",
    "    for i in range(len(X)):\n",
    "        if Y[i] == 1:\n",
    "            neg_X.append(X[i])\n",
    "        else:\n",
    "            pos_X.append(X[i])\n",
    "#     print(len(pos_X))\n",
    "#     print(len(neg_X))\n",
    "    \n",
    "    # 正样本欠采样\n",
    "    random.shuffle(pos_X)\n",
    "    pos_X = pos_X[:-under_sample]\n",
    "    # 负样本数据增强\n",
    "    neg_X2 = []\n",
    "    for x in neg_X:\n",
    "        random.shuffle(x)\n",
    "        neg_X2.append(x)\n",
    "        random.shuffle(x)\n",
    "        neg_X2.append(x)\n",
    "    neg_X.extend(neg_X2)\n",
    "    \n",
    "#     print(len(pos_X))\n",
    "#     print(len(neg_X))\n",
    "    \n",
    "    pos_Y = np.zeros(shape=[len(pos_X)], dtype=np.int32)\n",
    "    neg_Y = np.ones(shape=[len(neg_X)], dtype=np.int32)\n",
    "    \n",
    "    return pos_X+neg_X, np.append(pos_Y, neg_Y)\n",
    "\n",
    "train_X, train_Y = data_augmentation(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dbfdc17d0543>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in train_X:\n",
    "    index += 1\n",
    "    if len(x)==0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106123"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_num = 0\n",
    "for x in train_X:\n",
    "    if len(x)>=20:\n",
    "        len_num += 1\n",
    "len_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[62, 143]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(np.array(['dsjdhsjhdsdh make love']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['does', 'a', 'that', 'to', 'or', 'in', 'if', 'the', 'how', 'can', 'have', 'and', 'of', 'what', 'you', 'be', 'from', 'an', 'why', 'on', 'with', 'which', 'are', 'your', 'do', 'my', 'i', 'is', 'it', 'for']\n"
     ]
    }
   ],
   "source": [
    "def get_key (dict, value):\n",
    "    return [k for k, v in dict.items() if v <= value]\n",
    "print(get_key(tokenizer.word_index, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    9,    48,  6683,  7219,   158,    55,  6107,    36,     4,\n",
       "         1206,     6,     1,  8333,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [   11,    14,    24,    29,  3864,   498,     9,    35,    14,\n",
       "         3672,    37,     5,  3089,    10,    44,  1846,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [   16,    26,  2002,   374,    70,    26,  2002,   374,   451,\n",
       "         5546,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    9,    48, 13005,  8284, 52192,   119,     1, 39877, 28269,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [   15,     8,  1130, 42987, 99430,   911,     5,     4,  3133,\n",
       "         1533,    46,    96,  1465,     1,  9340,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = pad_sequences(train_X, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "train_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,    48,  6683,  7219,   158,    55,  6107,     0,     0,\n",
       "         1206,     0,     0,  8333,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,  3864,   498,     0,     0,     0,\n",
       "         3672,     0,     0,  3089,     0,    44,  1846,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,  2002,   374,    70,     0,  2002,   374,   451,\n",
       "         5546,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,    48, 13005,  8284, 52192,   119,     0, 39877, 28269,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,  1130, 42987, 99430,   911,     0,     0,  3133,\n",
       "         1533,    46,    96,  1465,     0,  9340,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.where(train_X>=40, train_X, 0)\n",
    "train_X[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
